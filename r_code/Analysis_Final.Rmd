---
title: "Buzz vs. Bite"
subtitle: "An Analysis of Alcohol Content and Bitterness in American Craft Beers"
date: "June 26, 2018"
output:
  pdf_document: 
    keep_tex: true
  html_document:
    df_print: paged
header-includes:
- \usepackage{amsmath}
- \usepackage{mathtools}
- \usepackage{float}
- \usepackage{xcolor,pifont}
- \newcommand{\cmark}{\Large\textcolor{green}{\ding{52}}}
- \newcommand{\xmark}{\Large\textcolor{red}{\ding{55}}}
- \usepackage{blindtext}
- \usepackage[utf8]{inputenc}
---

<!-- \documentclass{article} -->
<!-- \title{Buzz vs. Bite} -->
<!-- \subtitle{An Analysis of Alcohol Content and Bitterness in American Craft Beers} -->
<!-- \date{\today} -->


<!-- \author{Peter Flaming} -->
<!-- \author{Matthew Trevathan} -->
<!-- \author{Quinton Nixon} -->
<!-- \author{Brock Friedrich} -->

##Introduction
It goes without saying that entering the craft beer market, in pretty much any state, is a monstrous task. The explosion of micro-breweries has spread expeditiously in nearly every rapidly-growing urban environment. Luckily for you, the explosion is not in isolation. Demand has never been higher for unique and complex alcoholic libations. Where once the thought process was "the simpler the better," newer generations are constantly on the hunt for a drinking experience that fits their lifestyle and temperament. Although the market may seem saturated in many areas, it is, in reality, a rich field filled with almost never-ending demand ready to be tapped by the right combination of ingenuity, experimentation and a knowledge of what sells.

##Purpose of this study
Purpose of this study
  * To organize and analyze a list of 2410 craft beers from the United States and a list of 558 breweries.
  * To help you identify trends within this data to help narrow your focus for production. Manufacturing a beer that will outsell your competitors is more than just a quality product, it's knowing what quality is proven to sell.
  * To provide you with a functional list of each beer's alcohol content, bitterness level, style and other information to help you decide which direction to take your production facilities and supply chain.


## Loading required libraries

The following code loads useful libraries that aren't included in base R.  The
of these libraries come from the "tidyverse" including dplyr for manipulating
dataframes, tidyr for making data tidy, knitr for creating reproducible documents
ggplot2 for plots, maps for help with geographic plots, RColorBrewer for improved
map graphics, summarytools for summarizing data, magrittr for better code, and
gridExtra to assist with plots


```{r echo = FALSE, output = FALSE}

require(dplyr)
require(tidyr)
require(knitr)
require(ggplot2)
require(maps)
require(RColorBrewer)
require(summarytools)
require(magrittr) 
require(gridExtra)
#automatically set working directory to the directory containing this R script

opts_chunk$set(results = 'asis') # table format option
opts_chunk$set(fig.align = 'center') # plot align option
opts_chunk$set(fig.width = 10) # plot width
opts_chunk$set(fig.height = 10) # plot height
opts_chunk$set(message = FALSE) # output messages
opts_chunk$set(warning = FALSE) # output warnings
opts_chunk$set(error = FALSE) # output errors

ggplot2::theme_set(ggplot2::theme_bw())

abv_fill <- '#ffbe4f'
avb_outline <- '#cc983f'

ibu_fill <- '#6bd2db'
ibu_outline <- '#55a8af'

misc_cool = '#0c457d'
misc_warm = '#e8702a'

```

## Breweries Data

### Import Breweries

In this section we load and begin cleaning the data in order to aid our
exploratory analysis.  Column names are set to lowercase for ease of reading and we begin to summarize the data.

```{r}


#import breweries data
breweries_data <- read.csv("../data/Breweries.csv", header=TRUE)


colnames(breweries_data) %<>% tolower #lower case colnames

breweries_data %<>% rename(brewery_id = brew_id) #rename


```

### Inspect Raw Breweries Dataset

```{r}

# count breweries by state
brewery_summary_raw <- select(breweries_data, state, brewery_id) %>% #select columns
                   dplyr::group_by(state) %>% #group by
                   dplyr::summarize_all(funs(n_distinct(.))) %>%
                   arrange(desc(brewery_id))



# print top 5 states with the most breweries
kable(head(brewery_summary_raw, 5), digits = 0)

# print bottom 5 states with the most breweries
kable(tail(brewery_summary_raw, 5), digits = 0)

ggplot(brewery_summary_raw) +
      geom_bar(aes(x = reorder(state, -brewery_id, FUN=max),
                   y = brewery_id), 
               stat ="identity",
               fill = misc_cool) +
      guides(fill=guide_legend(title= NULL)) +
      xlab(NULL) +
      ylab("Number of Beer Styles") +
      scale_y_continuous(breaks = c(0, 10, 20, 30, 40, 50), 
                         limits = c(0, 50), 
                         minor_breaks = c(5, 15, 25, 35 ,45)) +
      ggtitle("Count of Beer Styles by State") +
      theme(plot.title = element_text(hjust = 0.5)) + # center plot title
      theme(text = element_text(size=10),
            axis.text.x = element_text(angle=90, hjust=1)) # rotate x-axis labels
```

### Clean Breweries Data

Before we can confidently proceed with our analysis it's important to ensure
we have scrubbed the data, removed duplicates, and decide how we will deal with errors and missing values.

We start this process by removing punctuation and whitespace from columns.  Humans are fallible and typos are easy to make.  Without knowing the origin of the data in the files provided, its prudent to assume that mistakes have been made and take measures to correct them.

Remvoing punctuation allows us to mitigate the possibility of commas being
erroneously typed as periods.  "Detroit, MI", for example, would be identified as a different city than "Detroit. MI"  Removing punctuation resolves this issue. Both city/state combinations simply become "Detroit MI."

Likewise, it's helpful to remove whitespace.  Although whitespace can appear
"invisible" to the human eye, computers can "see" this space as if it were a
number or a letter.

We use the apply function to make these changes to every row in the dataframe.

Removing duplicates is more of a challenge.  Before we can remove duplicates we need to confirm whether or not two rows are the same.  We identify duplicates by creating a unique key for each brewery that's a combination of the brewery ID, city, and state.  

De-duplicating in this case is a multi-step process.  We start by identifying brewery ids that show up more than once which indicate possible duplicates. Further investigation determines whether or not they are actually duplicates.

In addition to removing identifying and removing duplicates programatically, we also need to correct a few entries manually. There are some entries that are clearly mis-spelled and need to be addressed.

Once potential duplicates are identified and assigned temporary keys, they are evaluated apart from the main dataset and returned to the main dataset once duplicates have been removed.


1) Remove punctuation and trim whitespace

```{r}

# remove punctionation from all columns and trim whitespace
breweries_data <- as.data.frame(
                      apply(breweries_data #data set
                            , 2 #apply function column-wise
                            , function(x) trimws(gsub('[[:punct:] ]+',' ',x))) #anonymous function to remove punctuation and trim whitespace
                            , stringsAsFactors = FALSE)  #do not implicitly convert strings to factors


breweries_clean <- distinct(breweries_data, brewery_id, .keep_all = TRUE) %>% rename(brewery_name = name) # select distinct breweries according to the unique composite key and rename



```

2) Configure column types

```{r}

breweries_data$name <- as.factor(breweries_data$name) # convert Name column to factor
breweries_data$brewery_id <- as.integer(breweries_data$brewery_id) # convert Brew_ID to integer


```

3) Identify and capture potential duplicate records

```{r}

# confirm Brew_ID + City + State is a unique key
breweries_summary <- 
  select(breweries_data, brewery_id, city, state, name) %>%
  group_by(name) %>%
  summarize_all(funs(
    count = n_distinct(brewery_id, city, state))) %>%
  select(name, brewery_id_count) %>% # select only Name and Brew_ID_count columns
  arrange(desc(brewery_id_count)) # sort by Brew_ID_count desc
 

# capture potential duplicates
breweries_dups <- filter(breweries_summary, brewery_id_count > 1) # if Brew_ID_count > 1 then there is a potential duplicate on that Brew_ID

# rejoin potential dups to original dataset
breweries_dups <- select(breweries_dups %>% inner_join(breweries_data, by="name"), -ends_with("_count"))

breweries_dups

```

4) Correct duplicates

    * City name "Menominie" misspelled as "Menominee"

```{r}

# Fix Brew_ID=378, change City(Menominee -> Menominie) 
breweries_dups <- breweries_dups %>%
     mutate(city=replace(city, brewery_id==378, "Menominie")) %>%
     as.data.frame()


```

    * Marquette is not a city name in Massachusetts. Changed to Michigan based on other records existing for Marquette, MI, in addition to validating the location of the city on Google Maps.


```{r}


# Fix Brew_ID=96, change State(MA -> MI)
breweries_dups <- breweries_dups %>%
     mutate(state=replace(state, brewery_id==96, "MI")) %>%
     as.data.frame()


```

    * Merge duplicates into single records on name + city + state

```{r}


# group corrected duplicates to 
breweries_dups <- breweries_dups %>%
                  group_by(name, city, state) %>%
                  filter(n()>1)

```

    * Create new brewery_id for corrected duplicates

```{r}

# create surrogate keys for duplicates
breweries_sk <- breweries_dups %>%
                    group_by(name, city, state) %>%
                    summarize_all(funs(
                        brew_sk = (sum(brewery_id)*sum(brewery_id)),
                        count = n()
                        )) %>%
                    ungroup() %>%
                    right_join(breweries_dups, by = c("name", "city", "state")) %>% # rejoin to dupes by name, city, state
                    rename(old_brewery_id=brewery_id, new_brewery_id=brew_sk)
              
  
breweries_sk

```

    * Update original breweries dataset with corrections and de-duped records

```{r}

# create cleaned dataset

breweries_clean <- dplyr::bind_rows( # append rows of dataframes together
                          breweries_data %>% 
                            filter(!brewery_id %in% breweries_sk$old_brewery_id), # remove duplicated records from breweries_data
                          breweries_sk %>% 
                            rename(brewery_id=new_brewery_id) %>% # rename new_brewery_id to brewery_id so the rbind works
                            select(-count, -old_brewery_id)) %>% # remove extra columns from brewery_sk data frame
                          rename(brewery_name = name) %>% #change column name "name" to "brewery_name"
                          mutate(state = as.factor(state))

summarytools::dfSummary(breweries_clean)

```

## Clean Beer Data

A similar process is used to remove duplicates from the Beers dataset.

```{r}

beer_data <- read.csv("../data/Beers.csv", header=TRUE)

head(beer_data)
nrow(beer_data)

colnames(beer_data) %<>% tolower #lower case colnames





beer_clean <- merge(beer_data, # first data frame
             (breweries_sk %>% select(old_brewery_id, new_brewery_id)), # second data frame
             by.x = "brewery_id", # left table join key
             by.y = "old_brewery_id", # right table join key
             all = T) %>% # keep all columns
       mutate(brewery_id = ifelse(!is.na(new_brewery_id), new_brewery_id, brewery_id)) %>%  # update brewery_id with new_brewery_id, if new_brewery_id is not null
       select(-new_brewery_id) %>% # drop new_brewery_id column
       rename(beer_name = name)


summarytools::dfSummary(beer_clean)



```


## Question 1

To determine the number breweries in each state we simply count the number of times each state appears in the table. 

The prominent brewing states with twenty or more breweries include: Colorado 47, California 39, Michigan 32, Oregon 29, Texas 28, Pennsylvania 25, Massachusetts 23, Washington 23, Indiana 22, Wisconsin 20. 

These prominent brewing states are important to the beer market, because of their distinct beer types and styles that are produced in state and consumed nationally. 

What kinds of beers and their characteristics will be of great interest for the analysis.  

```{r}




#TODO: break up chunk

state_ll <- read.csv("../data/state_coords.csv") %>% 
                    mutate(State = toupper(State)) %>% 
                    rename(name = State, lat_center = Latitude, lon_center = Longitude)
        

states <- map_data("state") %>%
          mutate(region = toupper(region)) %>%
          rename(name=region) %>%
          select(long, lat, name, group)
 
# states %>% group_by(name) %>%
#             summarise_all(funs(n=n()))
# 
#        
states <- states %>%          
          left_join(
            states %>%
            group_by(name) %>%
            summarise_all(funs(n=n())) %>%
            select(name, group_n) %>%
            distinct(name, .keep_all = TRUE)
          )
          
          



breweries_by_state <- select(breweries_clean, brewery_id, state) %>%
  group_by(state) %>%
  summarise_all(funs(brewery_count = n()))  %>%
  left_join(state_ll, by=c("state" = "Abbr"))


# state_ll %>%
#   inner_join(states)



summarytools::dfSummary(breweries_by_state, transpose = TRUE)




```



```{r}
#map of breweries by state

#one to many join of breweries by state
breweries_geo <- breweries_by_state %>%
                  inner_join(states, by = c("name" = "name"))

# map chart of brweeries_by_state
ggplot((breweries_geo %>% arrange(desc(brewery_count))), 
       aes(group = state, stat="identity")) +
  geom_polygon(aes(x = long, 
                   y = lat, 
                   group=group, 
                   fill=brewery_count), 
               color = "black") + 
  geom_text(data = (breweries_by_state %>% 
                    filter(!(state %in% c("AK", "DC", "HI")))), #filter to continental 50 states
            aes(x = lon_center, 
                y = lat_center, 
                label = as.character(brewery_count)),
            color = 'white'
            ) +
  guides(fill=guide_legend(title= "Brewery Count")) +
  scale_fill_continuous(breaks = seq(0,50, by = 5)) +
  coord_fixed(1.3) + # fix lat/long display ratio
  
  ggtitle("Breweries by State") + # set plot title
  theme(plot.title = element_text(hjust = 0.5)) + # center plot title
  theme(legend.position = "right",
        axis.title.x=element_blank(), # hide x axis title
        axis.text.x=element_blank(),  # hide x axis text
        axis.ticks.x=element_blank(), # hide x axis ticks
        axis.title.y=element_blank(), # hide y axis title
        axis.text.y=element_blank(),  # hide y axis text
        axis.ticks.y=element_blank()) # hide y axis ticks



```


## Question 2

In data science, like in life, sometimes less is more.  Instead of maintaining separate tables for breweries and beers, it's helpful to merge the two datasets into a single combined dataset.  

We do this by joining the two tables by the Brew_ID variable to create a new object variable named merged_data, which allows us to view the desired characteristics of beers produced by the prominent breweries. 

Those characteristics will be of high importance for the analysis of most deisired beers, and we can begin to get clues of the prominent beers when we programmatically arrange these data by the most frequent style name variable sorted by every brewery.

```{r}
# merge beer and breweries
merged_data <- breweries_clean %>%
               full_join(beer_clean, by="brewery_id")

kable(head(merged_data, 6), digits = 2)

kable(tail(merged_data, 6), digits = 2)




```



```{r}

# Plot Mean Brews per Brewery by State



brews_per_brewery <- select(merged_data, brewery_name, state) %>%
    group_by(state) %>% 
    summarise_all(funs(brews=n(), breweries = n_distinct(brewery_name))) %>%
                  inner_join(state_ll, by = c("state" = "Abbr"))


ggplot((breweries_geo %>% arrange(desc(brewery_count))), 
       aes(group = state, stat="identity")) +
  geom_polygon(aes(x = long, 
                   y = lat, 
                   group=group, 
                   fill=brewery_count), 
               color = "black") + 
  geom_text(data = (brews_per_brewery %>% 
                    filter(!(state %in% c("AK", "DC", "HI")))), 
            aes(x = lon_center, 
                y = lat_center, 
                label = as.character(round((brews/breweries),1))),
            color = 'white'
            ) +
  guides(fill=guide_legend(title= "Mean Brews")) +
  scale_fill_continuous(breaks = seq(0,50, by = 5)) +
  scale_colour_manual(values=abv_fill) +
  coord_fixed(1.3) + # fix lat/long display ratio
  ggtitle("Mean Brews per Brewery by State") + # set plot title
  theme(plot.title = element_text(hjust = 0.5)) + # center plot title
  theme(legend.position = "right",
        axis.title.x=element_blank(), # hide x axis title
        axis.text.x=element_blank(),  # hide x axis text
        axis.ticks.x=element_blank(), # hide x axis ticks
        axis.title.y=element_blank(), # hide y axis title
        axis.text.y=element_blank(),  # hide y axis text
        axis.ticks.y=element_blank()) # hide y axis ticks

```



## Question 3

Sometimes data are not available.  This analysis is no exception.  To better understand how our analysis could be impacted by missing values we first have to identify and county them. 

These missing values would interfere with our analysis of center for the numeric variables and frequency of our factor and character variables. Once the missing values are removed, we can use the clean data to conduct the descriptive and quantitative analysis.

Below is a count missing values by variable.

```{r}

# Number of nulls in each column
kable(merged_data %>%
  select_if(function(x) any(is.na(x))) %>% 
  summarise_all(funs(sum(is.na(.))))
)

```


## Question 4

Computing the median is straightforward.  We simply merge all of the cleaned data by state, and calculate the median ABV and IBU for each state, which is summarized into a table and plotted as bar charts recording the median values across each state side by side. 

This plot is benificial to the analysis, because it gives insight into the beer characteristics of the prominent brewing states and the other states with less than twenty breweries. The prominent brewing states all share high ABV and IBU values, which brings more evidence to investigate for the analysis.

Are high ABV and IBU values always a characteristic of highly demanded beers in the respective market? We will have to produce a plausable claim and conduct a hypothesis test of that claim after further investigation.

```{r fig.height = 12, fig.width = 12} 


#TODO: Make bar plot pretty

merged_by_state <- select(merged_data, state, abv, ibu) %>%
                   group_by(state) %>%
                   summarise_all(median, na.rm = TRUE)#funs(median(!is.na(.)))) #TODO: Double check this is calculating correctly

merged_by_state$state <- as.factor(merged_by_state$state)  

#kable(as.data.frame(summarytools::descr(beer_clean)),digits = 2)


#TODO: facet by state

ggplot(merged_by_state, aes(x=state, y=abv)) +
  geom_bar(stat = "identity", position = "dodge") +
  ylim(0, .075) +
  #facet_grid(state ~ .) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 

ggplot(merged_by_state, aes(x=state, y=ibu)) +
  geom_bar(stat = "identity", position = "dodge") +
  #ylim(0, .075) +
  #facet_grid(state ~ .) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 


```


## Question 5

Before you can "push the limits" you have to know what the limits are.  We want
to determine which state has the most alcoholic beer and which state has the most
bitter beer.

This is relatively simple.  We can determine this visually using boxplots and
confirm programmatically by sorting the tables in descending order based on the
values of interest.

The state with the highest ABV value is Colorado with a 0.128 ABV value for the Lee Hill Series Vol. 5 - Belgian Style Quadrupel Ale beer that is a Quadrupel (Quad) style of beer brewed by the Upslope Brewing Company in Boulder, CO.

The state with the highest IBU value is Oregon with a 138 IBU value for the Bitter Bitch Imperial IPA beer that is a American Double / Imperial IPA style of beer brewed by the Astoria Brewing Company in Astoria, OR.

The states with the highest ABV and IBU values are found to be comprised of a majority of the prominent brewing states including the folling values State(maxABV, maxIBU): 

Colorado(.128, 104), California(.099, 115), Michigan(.099, 115), Oregon(.082, 138), Texas(.099, 118), Pennsylvania(.099, 113), Massachusetts(.099, 130), Washington(.084, 83), Indiana(.120, 115), Wisconsin(.099, 80). 

```{r}

  

ggplot((merged_data %>% na.omit(abv)), 
       aes(x=state , y=abv)) +  #TODO: Move to Appendix
  geom_boxplot() +
  #ylim(0, .075) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 
 
ggplot((merged_data %>% na.omit(ibu)), 
       aes(x=state , y=ibu)) +  #TODO: Move to Appendix
  geom_boxplot() +
  #ylim(0, .075) +
  theme(text = element_text(size=10),
        axis.text.x = element_text(angle=90, hjust=1)) 
 
max_abv <-  (select(merged_data, state, abv) %>%
                   group_by(state) %>%
                   #filter(ABV == max(ABV)) %>%
                   arrange(desc(abv))  %>% #sort by ABV
                   filter(row_number() == 1))[1,] #get first row
          
max_abv


max_ibu <-  (select(merged_data, state, ibu) %>%
                   group_by(state) %>%
                   #filter(ABV == max(ABV)) %>%
                   arrange(desc(ibu))  %>% #sort by ABV
                   filter(row_number() == 1))[1,] #get first row
          
max_ibu



```


## Question 6

The amount of alcohol by volume ABV is a good representation of the beer market, where consumer demand is infered from the geographical spread and number of breweries produce a certain style of beer. The certain style of a beer is controlled in-part by the ABV content. From the ABV five number summary we can better describe the use of the ABV variable as a controlling factor in the consumer market of beer. 

The minimum ABV value of 0.001 is represented only one style of beer -Low Alcohol Beer produced by 1 brewery in CA:1. From these data we can infer the lack of consumer demand by the geographical spread of the style and by the lack of 0.001 ABV variability. 

The first quartile(Q1) is represented by beers with a 0.050 ABV value represented by the -American -IPA and -Ale styles of beer that ranges from 5-100 in IBU. There are 38 different styles of beers with this ABV, that are produced by 141 different breweries in 46 different states AK:3, AL:1, AR:1, AZ:3, CA:10, CO:12, CT:3, DC:1, FL:5, GA:1, HI:1, IA:3, ID:2, IL:4, IN:3, KS:2, KY:1, LA:3, MA:4, MD:2, ME:2, MI:8, MN:3, MO:3, MS:1, MT:3, NC:4, ND:1, NE:1, NH:1, NJ:1, NV:1,  NY:1, OH:6, Ok:1, OR:8, PA:5, RI:1, SC:1, TN:1, TX:5, UT:2, VA:2, WA:2, WI:7, WY:2. The use of a 0.050 ABV for a beer will allow for a large amount of variation with respect to the IBU of a beer style. The use of an ABV of 0.050 with any IBU between 5-100 will likely be a higly demanded beer by the consumer market.   

The median ABV value of 0.056 represents the -American Ale and -Pale Ale styles of beer that ranges from 4-70 in IBU. There are 21 different styles of beers with this ABV, that are produced by 49 different breweries in 25 different states AK:1, AL:1, CA:5, CO:6, FL:1, IA:1, ID:1, IL:2, IN:2, KS:1, MA:3, MI:4, MN:2, MO:1, MT:1, NC:1, NE:1, NH:1, NY:1, OR:1, PA:4, TX:3, VA:2, WA:1, WI:2. 

The third quartile(Q3) is represented by beers with a 0.067 ABV value represented by the -IPA and -Ale styles of beer that ranges from 33-85 in IBU. There are 10 different styles of beers with this ABV, that are produced by 22 different breweries in 15 different states AZ:1, CA:2, CO:3, MA:1, ME:1, MI:4, MN:2, NC:1, ND:1, NY:1, OH:1, OR:4, PA:1, WA:1, WV:1.  

The maximum ABV value of 0.128 is represented only one style of beer -Quadrupel (Quad) that is produce by 3 breweries from 3 different states CO:1, IN:1, MI:1, and we can infer the demand of the consumer as a moderate demand by the breweries producing these beer being spread out geographically across the nation even though the style variability is very-low for the 0.128 ABV.

Summarizing the statistics for ABV can be accomplished in a signle command.

```{r}

#summaryize ABV

# tidy_summary <- tidy(summary(merged_data$ABV)) #For some reason this line wont knit


abv_stats <- as.data.frame(t(summary(merged_data$abv))) %>% #summarize and transpose
             rename("abv"=Freq, Statistic=Var2) %>%
             select(Statistic, abv)


abv_stats$abv <- round(abv_stats$abv, digits = 3)
  

abv_stats #TODO: Add IQR, stdev    #TODO: Compare to quinton's summary




```


## Question 7

To determine the relationship between ABV and IBU it's helpful to see all values
for both variables at the same time.  This is most easily accomplished using
a scatterplot.

Linear regression was used to model the relationship between ABV and IBU from a sample of cleaned data that was created in the previous questions above.

The equation:   

       y-intercept = IBU - slope * ABV       

was used to plot thw linear model for the ABV and IBU data in this study. 

With ABV on the x-axis and IBU on the y-axis, we start to see that there is a positive 
linear correlation between the ABV and IBU values, with R-squared = 0.44593.

R-squared is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination, and the definition of R-squared is fairly straight-forward; it is the percentage of the response variable variation that is explained by the linear model.

Since the creation, consumption, and  distribution of beer by methods of breweries is a human behavior, it is very important to note that it is common for studies to measure R-squared values less than 0.50. The reason is , that human behavior is harder to predict with linear models.

The outcome of our study measured an R-squared value of 0.44593 which is an awesome fit, and much better than we expected for this study to produce, since the study is based on the human behavior of beer consumption with respect to the variation of ABV and IBU accross the United States of America. 

Adding a trendline allows us to determine a formula that specifies this correlation. The regression is plotted and the results of the Spearman's Rank Correlation Test are in the following figures. 

###Spearman's Rank Correlation Results for rho
```r
data:  styles$ibu and styles$abv
S = 153570000, p-value < 2.2e-16
alternative hypothesis: true rho is not equal to 0
sample estimates:
rho 
0.6677798 

[1] 0.4459299
```
```{r fig.width = 10, fig.height = 10}


#A distinct list of beer styles, as classified by a unique style Name, IBU, ABV, and Ounces values.

styles <- beer_clean %>% 
              distinct(beer_id, style, ibu, abv, ounces) %>% 
              arrange(style) %>% 
              na.omit(ibu, abv)

```

* Plot ABV v. IBU

```{r fig.width= 10, fig.height = 10}

ggplot(styles, aes(x=abv, y=ibu)) +
  geom_point(color = misc_cool,
             size = 3) +
  theme(legend.position="none") +
  ggtitle("Alcohol Content v Bitterness") +
  xlab("Alcohol Content (ABV)") +
  ylab("International Bitterness Units (IBU)") +
  theme(plot.title = element_text(hjust = 0.5))

```

### Analysis of ABV and IBU

    + More info on Spearman test: https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php


* Problem: We wish to test if there is a monotonic association between the alochol by volume (ABV) and international bitterness unit (IBU) rating of beers selected from domestic craft breweries.

* Hypotheses:
    + H~o~: $\rho= 0$
    + H~A~: $\rho\neq 0$

<!-- <font color="red"> &#x2717; </font> -->
<!-- <font color="green"> &#x2713; </font> -->

* Assumptions:
    + Continuity of data:\cmark
    + Paired observations: \cmark
    + Data has linear relationship: \cmark 
    + No significant outliers:  \xmark
    + Normality: \xmark
    
```{r dpi = 400}

m_eqn = function(m) {

  l <- list(a = format(coef(m)[1], digits = 2),
      b = format(abs(coef(m)[2]), digits = 2),
      r2 = format(summary(m)$r.squared, digits = 3));

  if (coef(m)[2] >= 0)  {
    eq <- substitute(italic(y) == a + b %.% italic(x)*","~~italic(r)^2~"="~r2,l)
  } else {
    eq <- substitute(italic(y) == a - b %.% italic(x)*","~~italic(r)^2~"="~r2,l)    
  }

  as.character(as.expression(eq));                 
}

#Scatter plot of ABV v IBU
ggplot(styles, aes(x=abv, y=ibu)) +
  geom_point(color = misc_cool,
             size = 3) +
  geom_smooth(method = "lm", 
              se = FALSE, 
              color=misc_warm) +
  geom_text(aes(x = .045, 
                y = 125, 
                label = lm_eqn(lm(abv ~ ibu ,styles))), 
            parse = TRUE, 
            color = misc_warm) +
  theme(legend.position="none") +
  ggtitle("Alcohol Content v Bitterness") +
  xlab("Alcohol Content (ABV)") +
  ylab("International Bitterness Units (IBU)") +
  scale_fill_manual(values=) +
  theme(plot.title = element_text(hjust = 0.5))

```

#### QQ-Plot - Check for Normality

```{r fig.width= 10, fig.height=10}

# QQ Plots of IBU and ABV


#calulate line fit
y <- quantile((styles$ibu %>% na.omit()), c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
y_int <- y[1] - slope * x[1]

qq_ibu <- ggplot(styles, aes(sample = styles$ibu)) + 
              geom_qq(shape = 16, size = 2, alpha = 0.5) +
              geom_abline(slope = slope, intercept = y_int, colour ='red', size = 1) +
              ggtitle("QQ-Plot of IBU") +
              theme_bw()  +
              theme(plot.title = element_text(hjust = 0.5))


#calulate line fit
y <- quantile((styles$abv %>% na.omit()), c(0.25, 0.75))
x <- qnorm(c(0.25, 0.75))
slope <- diff(y)/diff(x)
y_int <- y[1] - slope * x[1]  

qq_abv <- ggplot(styles, aes(sample = styles$abv)) + 
            geom_qq(shape = 16, size = 2, alpha = 0.5) +
            geom_abline(slope = slope, intercept = y_int, colour ='red', size = 1) +
            ggtitle("QQ-Plot of ABV") +
            theme_bw() +
            theme(plot.title = element_text(hjust = 0.5))


grid.arrange(qq_abv, qq_ibu)



```

#### Histogram - Check for Normality

```{r}


# Histograms of IBU and ABV

hist_ibu <- ggplot(styles %>% na.omit(ibu)) +
              geom_histogram(aes(x=ibu)) +
              theme(text = element_text(size=10),
                  axis.text.x = element_text(angle=90, hjust=1)) 

hist_abv <- ggplot(styles %>% na.omit(abv)) +
              geom_histogram(aes(x=abv)) +
              theme(text = element_text(size=10),
                  axis.text.x = element_text(angle=90, hjust=1)) 


grid.arrange(hist_abv, hist_ibu)


```

#### Boxplot - Check for Outliers

```{r fig.height = 3, fig.width = 10}

# Boxplots of IBU and ABV


ibu_outliers <- boxplot(styles$ibu, plot = FALSE)[["out"]]

abv_outliers <- boxplot(styles$abv, plot = FALSE)[["out"]]


x<-boxplot(styles$ibu, plot = FALSE)

bp_abv <- ggplot((styles %>% drop_na(abv)), aes(x="", y=abv)) +
      geom_point(aes(fill = ifelse((abv %in% abv_outliers),"Outlier","Valid")), 
                 size = 4, 
                 shape = 21, 
                 position = position_jitter())+
      stat_boxplot(geom ='errorbar') +
      geom_boxplot(alpha=.5, 
                   outlier.shape = NA) +
      guides(fill=guide_legend(title= NULL)) +
      xlab("Beer Styles") +
      ylab("Alcohol by Volume (ABV)") +
      scale_y_continuous(position = "right", 
                         breaks = c(.025, .05, .075, .1, .125), 
                         limits = c(0.025, .125)) +
      coord_flip()


bp_ibu <- ggplot((styles %>% drop_na(ibu)), aes(x="", y=ibu)) +
      geom_point(aes(fill = ifelse((ibu %in% ibu_outliers),"Outlier","Valid")),
                 size = 4, 
                 shape = 21, 
                 position = position_jitter())+
      stat_boxplot(geom ='errorbar') +
      geom_boxplot(alpha = .5, 
                   outlier.shape = NA) +
      guides(fill=guide_legend(title= NULL)) +
      xlab("Beer Styles") +
      ylab("International Bitterness Units (IBU)") +
      scale_y_continuous(breaks = c(0, 25, 50, 75, 100, 125, 150), 
                         limits = c(0, 150)) +
      coord_flip()

grid.arrange(bp_abv, bp_ibu)



```

  + Due to the lack of normality of the IBU variable and the presence of outliers in both variables, we will use the Spearman Rank-Correlation test as an alternative to the preferred Pearson Correlation.


#### Significance Testing: Spearman Rank-Order Correlation

    + More info on Spearman test: https://statistics.laerd.com/statistical-guides/spearmans-rank-order-correlation-statistical-guide.php

* Hypotheses: 
    + H~o~: $\rho= 0$
    + H~A~: $\rho\neq 0$
```{r results='markup'}

# Significance test
spear_test_result <- cor.test(styles$ibu, styles$abv, method = "spearman", conf.level = .05, exact=FALSE)

spear_test_result

r_sq <- spear_test_result[["estimate"]][["rho"]]^2 # capture r-squared

r_sq

```


#### Conclusion

There is strong evidence that the ABV and IBU are positively associated (p-value < 0.001 from a Spearman Rank-Order Correlation).  At a 95% confidence level, the IBU rating accounts for `r round(r_sq*100, 2)`% of the variation in the ABV.  While IBU and ABV certainly have a correlation, the correlation is weak ($r^2 =$ `r round(r_sq, 2)`).  Thus, we reject the null hypothesis that IBU rating and ABV are un-corrolated across the beer styles in our sample.  Beer styles were not randomly assigned to any treatment and we do not know if the beer data were randomly selected, so we must limit our results to indicating an association between IBU rating an ABV.  No causality or inferences to larger populations can be drawn.   


## Appendex

```{r}



```


#### Session Info

```{r}

sessionInfo()

```




